{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 접근 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline의 Randomforest 지도학습 결과를 보았을 때 0.997 정도의 매우 높은 성능을 보여 Level7만 잘 구별한다면 좋은 성능을 얻을 수 있을 것이라고 생각했습니다.\n",
    "\n",
    "7을 구별하기 위해서 비지도 학습으로 접근을 시도했고 오토인코더, one-class-svm, isolated-randomforest 등의 비지도 학습 방법을 적용해 보았으나 기존과 단어 몇개만 다른 경우들이 7 특성 떄문인지 성능이 좋지 않았습니다. 그 중에서 오토인코더가 성능이 괜찮았는데 \"렛서펜더\"님이 오토인코더 관련 코드를 올려주셨습니다. \n",
    "https://dacon.io/competitions/official/235717/codeshare/2677?page=1&dtype=recent\n",
    "\n",
    "\n",
    "결론적으로 로그 데이터의 전처리를 진행하고 Baseline에서 Validation을 통해 등급별로 threshold를 상세 설정한 점수가 가장 높게 나왔습니다.Threshold 를 잡아서 7을 잡았지만, Train 문장과 완전히 동일한 문장이 존재하는지 여부를 체크해주는 컬럼을 통해 문장 전체가 완전히 동일한 경우에는 Threshold 에 걸리지 않도록 했습니다. \n",
    "\n",
    "마지막으로 점수를 조금 향상하기 위해서 7 등급 이외의 등급은 전처리가 덜 진행된 데이터를 활용하여 베이스라인 지도학습을 다시 진행했습니다. (지나친 전처리는 0~6등급 지도 학습 분류에 악영향이라고 판단) \n",
    "\n",
    "\n",
    "실제 서비스에서 Line by Line으로 들어왔을 때의 분류방법:\n",
    "1. 로그 문장 데이터 전처리 진행 (Cleaning)\n",
    "2. train 데이터와 완전히 동일한 문장이 있는지 확인하여 서로 다른 모델 적용(A방법, B방법)\n",
    "3. 동일한 문장이 있다면 0~6 등급 지도 학습된 모델로 Predict(Threshold 적용 X) (A방법)\n",
    "4. 동일한 문장이 없다면 0~6 등급 지도 학습된 모델로 Predict 이후에 설정된 Threshold 를 통해 7은 따로 분류 (B방법)\n",
    "5. 4번에서 Threshold를 통해 걸러지지 않는다면 3번과 동일한 모델로 predict 적용 (A방법)\n",
    "\n",
    "\n",
    "[참고]  \n",
    "https://dacon.io/competitions/official/235717/codeshare/2536?page=1&dtype=recent (대회 베이스라인)  \n",
    "https://dacon.io/competitions/official/235717/codeshare/2539?page=1&dtype=recent (10duck 님의 데이터 전처리 및 EDA)  \n",
    "https://dacon.io/competitions/official/235717/support/403102?page=1&dtype=recent (taegu 님의 threshold 조정 문의 글)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Libaray IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pds\n",
    "from dask import dataframe\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "### 1. 다양한 기호 및 숫자 제거\n",
    "의미 없는 숫자와 기호들이 많아서 분류를 방해한다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "def mask(tt):\n",
    "    tt=tt.apply(lambda x: re.sub(r'(\\\\n)',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[^a-zA-Zㄱ-ㅣ가-힣0-9:=\\s\\(\\)./,\\<\\>]+',' ',x))\n",
    "    #tt=tt.apply(lambda x: re.sub(r' ?(?P<note>[:=\\(\\)./,\\<\\>]) ?', ' \\g<note> ', x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[0-9]+',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r\"':/()\",' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r':',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r',',' ',x))\n",
    "    # = tt.apply(lambda x: re.sub(r'(',' ',x))\n",
    "    #t = tt.apply(lambda x: re.sub(r')',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',' ',x))\n",
    "    for st in lit:\n",
    "        st = \" \"+st + \" \"\n",
    "        tt=tt.apply(lambda x: re.sub(st,' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    \n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pre_log'] = mask(train.full_log)\n",
    "test['pre_log'] = mask(test.full_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 영어 단어가 아니거나 3글자 미만인지인 경우에는 삭제\n",
    "Validation 7등급을 보았을 때, 단어들이 의미가 있는 영어 단어들이 새로 들어오는 경향이 있다고 판단했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#포함되어 있는 단어 모음 생성\n",
    "def count_word(data):\n",
    "    tem = list(data['pre_log'].str.split(\" \"))\n",
    "    all_word = []\n",
    "    for word in tem:\n",
    "        all_word.extend(word)\n",
    "    words = pd.Series(all_word)\n",
    "    return words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = count_word(train)\n",
    "test_count = count_word(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = list(set(train_count.index))\n",
    "test_words = list(set(test_count.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영어 단어 + 3글자 이상인 경우만 True\n",
    "from nltk.corpus import words\n",
    "def check_words(word_list: list):\n",
    "    re = [False] * len(word_list)\n",
    "    for i,word in enumerate(word_list):\n",
    "        if len(word) < 3:\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        if word in words.words():\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "word_list = ['Promiscuous', 'ab', 'nihongo', 'abstract', 'pedo','gid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, False, True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check_words는 단어인지를 확인해주고 결과를 t/f로 반환\n",
    "check_words(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = check_words(train_words)\n",
    "test_tf = check_words(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어인지 확인해주는 딕셔너리 만들어주기 (train_isword,test_isword)\n",
    "train_isword = dict()\n",
    "test_isword = dict()\n",
    "\n",
    "total_words = list(train_words)\n",
    "test_words = list(test_words)\n",
    "\n",
    "for i in range(len(train_words)):\n",
    "    train_isword[train_words[i].lower()] = train_tf[i]\n",
    "    \n",
    "for i in range(len(test_words)):\n",
    "    test_isword[test_words[i].lower()] = test_tf[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train, Test 에 각각 적용\n",
    "##### 아래의 nltk 패키지를 이용해 영어가 아닌 단어를 제거하는 방법은 두가지를 소개 하였습니다. 결과는 동일하며 시간 측면에서 아래의 방식이 빠르기 때문에 느린 방법을 주석처리 하였습니다.  (위는 주석 처리)\n",
    "\n",
    "- 모든 문장에 개별적으로 접근하여 영어가 아닌 단어를 제거하는 코드 (60~70 시간소요)\n",
    "- 미리 사용된 단어들을 모아서 딕셔너리를 만들어서 사용한 경우(약 10분)\n",
    "\n",
    "두가지 방법을 모두 소개한 이유는 아래의 방식은 TEST DATA를 모으는 행위인 Data Leakage 문제가 발생할 수 있다는 점 때문입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#단어를 하나씩 확인하는 방법(60~70 시간 이상 소요)\n",
    "from nltk.corpus import words\n",
    "def check_words(word_list: list):\n",
    "    re = [False] * len(word_list)\n",
    "    for i,word in enumerate(word_list):\n",
    "        word = word.lower()\n",
    "        if len(word)>2:\n",
    "            if word in words.words():\n",
    "                re[i] = True\n",
    "    return re\n",
    "\n",
    "def cutt(data):\n",
    "    data = data.lower() \n",
    "    splited = data.split(\" \")\n",
    "    check = check_words(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])\n",
    "    tem = \" \".join(real_words)\n",
    "    return tem\n",
    "\n",
    "#valid['cut'] = valid['pre_log'].map(cutt)\n",
    "train['cut']  =train['pre_log'].map(cutt)\n",
    "test['cut']  =test['pre_log'].map(cutt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def checking_train(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if train_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "\n",
    "def checking_test(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if test_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "\n",
    "\n",
    "def cutt_train(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_train(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])    \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower() \n",
    "    return tem\n",
    "\n",
    "def cutt_test(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_test(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])  \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower()\n",
    "    return tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cut'] = train['pre_log'].map(cutt_train)\n",
    "test['cut'] = test['pre_log'].map(cutt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['full_log']\n",
    "del test['full_log']\n",
    "\n",
    "del train['pre_log']\n",
    "del test['pre_log']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.to_csv(\"sub_train3.csv\",index=False)\n",
    "test.to_csv(\"sub_test3.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.to_csv(\"only_train.csv\",index =False)\n",
    "test.to_csv(\"only_test.csv\",index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 나중에 사용될 inornot 리스트\n",
    "\n",
    "train 데이터에 100퍼센트 동일한 문장이 있는지 확인해주는 변수 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6544"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bag = train['cut'].unique()\n",
    "len(train_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1418916/1418916 [05:22<00:00, 4396.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#inornot을 통해서 train안에 같은 문장이 있으면 0 없으면 1\n",
    "from tqdm import tqdm\n",
    "inornot = np.zeros(len(test))\n",
    "for i in tqdm(range(len(test))):\n",
    "    tem = test.iloc[i]['cut']\n",
    "    if tem not in train_bag:\n",
    "        inornot[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = pd.read_csv(\"sub_train3.csv\")\n",
    "test= pd.read_csv(\"sub_test3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>action with response code type unavailable exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>warn resurrect connection dead instance but go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>type log warning message error living share no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>warn resurrect connection dead instance but go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>rufus error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>start unable open file file read time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  level                                                cut\n",
       "0    0      0  type error warning collection level error erro...\n",
       "1    1      0  action with response code type unavailable exc...\n",
       "2    2      0  type error warning collection level error erro...\n",
       "3    3      0  type error warning collection level error erro...\n",
       "4    4      1  type audit arch success yes exit gid suid none...\n",
       "5    5      1  type audit arch success yes exit gid suid none...\n",
       "6    6      0  type error warning collection level error erro...\n",
       "7    7      0  warn resurrect connection dead instance but go...\n",
       "8    8      0  type error warning collection level error erro...\n",
       "9    9      0  type log warning message error living share no...\n",
       "10  10      1  type audit arch success yes exit gid suid none...\n",
       "11  11      0  type error warning collection level error erro...\n",
       "12  12      0  warn resurrect connection dead instance but go...\n",
       "13  13      0  type error warning collection level error erro...\n",
       "14  14      0                                        rufus error\n",
       "15  15      1  type audit arch success yes exit gid suid none...\n",
       "16  16      0              start unable open file file read time\n",
       "17  17      0  type error warning collection level error erro...\n",
       "18  18      0  type error warning collection level error erro...\n",
       "19  19      0  type error warning collection level error erro..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>action with response code type unavailable exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472967</th>\n",
       "      <td>472967</td>\n",
       "      <td>0</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472968</th>\n",
       "      <td>472968</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472969</th>\n",
       "      <td>472969</td>\n",
       "      <td>0</td>\n",
       "      <td>type log error task manager message poll for w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472970</th>\n",
       "      <td>472970</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472971</th>\n",
       "      <td>472971</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  level                                                cut\n",
       "0            0      0  type error warning collection level error erro...\n",
       "1            1      0  action with response code type unavailable exc...\n",
       "2            2      0  type error warning collection level error erro...\n",
       "3            3      0  type error warning collection level error erro...\n",
       "4            4      1  type audit arch success yes exit gid suid none...\n",
       "...        ...    ...                                                ...\n",
       "472967  472967      0                                              error\n",
       "472968  472968      1  type audit arch success yes exit gid suid none...\n",
       "472969  472969      0  type log error task manager message poll for w...\n",
       "472970  472970      0  type error warning collection level error erro...\n",
       "472971  472971      0  type error warning collection level error erro...\n",
       "\n",
       "[472972 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#남은 단어가 없는 경우에는 'missing' 으로 대체해주었습니다.\n",
    "train['cut'] = train['cut'].replace('','missing',regex=True)\n",
    "test['cut'] = test['cut'].replace('','missing',regex=True)\n",
    "\n",
    "\n",
    "\n",
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['cut'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100,random_state = 1 )\n",
    "forest.fit(train_features,train_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation을 통한 threshold 조절\n",
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 1))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 2))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.95) & (results == 3))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 4))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 5))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 6))[0]]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation을 통한 threshold 조절\n",
    "results[np.where((np.max(results_proba, axis=1)<0.94001) & (np.max(results_proba, axis=1) > 0.93999) & (results == 1))[0]]=7 \n",
    "results[np.where((np.max(results_proba, axis=1)<0.611657) & (np.max(results_proba, axis=1) > 0.6116568) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.571657) & (np.max(results_proba, axis=1) > 0.5716568) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.68001) & (np.max(results_proba, axis=1) > 0.67999) & (results == 5))[0]]=7 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002369\n",
       "1     396443\n",
       "3      12813\n",
       "5       6418\n",
       "7        780\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"tem_answer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가작업\n",
    "TEST 데이터에 동일한 문장이 있는지를 생성했던 컬럼을 추가해주는 작업입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['inornot'] = pd.Series(inornot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = submission[(submission['level']==7) & (submission['inornot'] == 0)].index\n",
    "not7_id = list(test.iloc[cal]['id'])\n",
    "pd.Series(not7_id).to_csv(\"not7_id.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 작업\n",
    "\n",
    "위의 방식으로 많이 전처리를 하면 7을 걸러내기 위한 threshold 를 잡기는 유리하지만, 지도 학습 자체의 성능은 떨어지는 것을 확인 하였습니다. 따라서, 7를 제외한 나머지 등급에는 전처리가 덜 진행된 Data로 지도학습 분류를 하였습니다. TfidfVectorizer이 더 성능이 우수하여 사용했습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_log']=train['full_log'].str.replace(r'[0-9]', '<num>')\n",
    "test['full_log']=test['full_log'].str.replace(r'[0-9]', '<num>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['full_log'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['full_log'])\n",
    "#ids=list(test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100,random_state = 1 )\n",
    "forest.fit(train_features,train_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002770\n",
       "1     396532\n",
       "3      12997\n",
       "5       6524\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "not7_id = pd.read_csv('not7_id.csv')\n",
    "not7_id = list(not7_id['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1002512\n",
       "1     396348\n",
       "3      12915\n",
       "5       6467\n",
       "7        581\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위에서 잡은 7 합치기 & train에 있는 경우는 사용하지 않기\n",
    "only = pd.read_csv(\"tem_answer.csv\")\n",
    "le7 = list(only[only['level']==7]['id'])\n",
    "le7_update = list((set(le7))-set(not7_id))\n",
    "print(len(le7))\n",
    "print(len(le7_update))\n",
    "idx = submission[submission['id'].isin(le7_update)].index\n",
    "submission.iloc[idx] = 7\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002512\n",
       "1     396348\n",
       "3      12915\n",
       "5       6467\n",
       "7        581\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who = submission.level\n",
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level'] = who\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"581_final_answer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
